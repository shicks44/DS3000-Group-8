# -*- coding: utf-8 -*-
"""V2Group_8_AI_detection_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hMIuzBzRQhEb9Hb9HvqnFZQq9GIkoKLC

<a href="https://colab.research.google.com/github/shicks44/DS3000-Group-8/blob/main/Group_8_AI_detection_CNN.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
BASE_PATH = kagglehub.dataset_download('shreyasraghav/shutterstock-dataset-for-ai-vs-human-gen-image')

print('Data source import complete.')

"""###IMPORTS"""

import os
import random
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# image handler
from PIL import Image

# basic train and test matrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report,
    roc_curve,
    roc_auc_score
)

# py torch
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# optimisers and schedulers
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau

# torch vision transforms and such
import torchvision
import torchvision.transforms as T
import torchvision.models as models
from torchvision.models import resnet18,ResNet18_Weights
# progress bar for waiting
from tqdm.auto import tqdm

"""##DATA SET LOADING"""

df = pd.read_csv(os.path.join(BASE_PATH, "train.csv"))
print(df.head())
print(df.columns)
print(df['label'].value_counts())

"""###SANITY CHECK"""

sample = df.sample(6)
plt.figure(figsize=(10,5))
for i, row in sample.iterrows():
    img = Image.open(os.path.join(BASE_PATH, row["file_name"])) # Fixed: Removed the extra "train_data"
    plt.subplot(2,3,list(sample.index).index(i)+1)
    plt.imshow(img)
    plt.title(f"Label: {row['label']}")
    plt.axis("off")
plt.show()

trainData = pd.read_csv(os.path.join(BASE_PATH, "train.csv"))
testData = pd.read_csv(os.path.join(BASE_PATH, "test.csv"))

print(trainData.head())

print("Dataset Info:")
print(trainData.info(), "\n")

print("Missing values per column:")
print(trainData.isnull().sum(), "\n")

if 'Unnamed: 0' in trainData.columns:
    trainData.drop(columns=['Unnamed: 0'], inplace=True)
print(trainData.columns)

plt.figure(figsize=(10, 6))
sns.countplot(x='label', data=trainData, palette='viridis')
plt.title('Distribution of AI (1) and real (0) Images')
plt.xlabel('Label')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

"""###SPLIT DATA
80% training 20% validation
"""

train_df, val_df = train_test_split(
    trainData,
    test_size=0.2,
    stratify=trainData["label"],
    random_state=42
)

print("Training Data size:", len(train_df),"\nValidation Data Size:",  len(val_df))

"""##IMAGE SIZING"""

train_tfms= T.Compose([
    T.Resize((224, 224)),
    T.RandomHorizontalFlip(),
    T.RandomRotation(10),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_tfms= T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])
])

"""##DETECTOR CLASS"""

class AIDetectDataset(Dataset):
    def __init__(self, df, transforms=None):
        self.df = df.reset_index(drop=True)
        self.transforms = transforms

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        img_path = os.path.join(BASE_PATH,row['file_name'])   # for train.csv
        # If you're using test.csv with 'id', use row['id'] instead

        img = Image.open(img_path).convert("RGB")

        if self.transforms:
            img = self.transforms(img)

        label = int(row["label"])   # 0 or 1
        return img, label

"""##DATA LOADERS"""

batch_size = 32

train_ds = AIDetectDataset(train_df, transforms=train_tfms)
val_ds   = AIDetectDataset(val_df,   transforms=val_tfms)

train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2, persistent_workers=True,pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2, persistent_workers=True,pin_memory=True)

# quick sanity check
images, labels = next(iter(train_loader))
print("Batch shape:", images.shape, "Labels sample:", labels[:8])

"""##DEFINING DEVICE (CPU OR GPU)"""

#David's changes

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)

for param in model.parameters():
    param.requires_grad = False  # freeze all layers

num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)  # new classification layer
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Load a ResNet18 pre-trained on ImageNet
model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)

# Replace the final fully connected layer to output 2 classes (0 = real, 1 = AI)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)

model = model.to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

"""##IMPLIMENTING RESNETS CNN MODEL"""

#David's changes


#History of epochs
train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []


num_epochs = 5

for epoch in range(num_epochs):
    print(f"\nEpoch {epoch+1}/{num_epochs}")
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    epoch_train_loss = running_loss / len(train_loader.dataset)
    epoch_train_accuracy = correct / total

    train_losses.append(epoch_train_loss)
    train_accuracies.append(epoch_train_accuracy)

    #### VALIDATION ####
    model.eval()
    val_running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_running_loss += loss.item() * images.size(0)

            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    epoch_val_loss = val_running_loss / len(val_loader.dataset)
    epoch_val_accuracy = correct / total

    val_losses.append(epoch_val_loss)
    val_accuracies.append(epoch_val_accuracy)

    print(f"Epoch [{epoch+1}/{num_epochs}]  "
          f"Train Loss: {epoch_train_loss:.4f}  Val Loss: {epoch_val_loss:.4f}  "
          f"Train Acc: {epoch_train_accuracy:.4f}  Val Acc: {epoch_val_accuracy:.4f}")

history = {"loss": [], "val_loss": [], "acc": [], "val_acc": []}
best_val_loss = float("inf")
num_epochs = 5  # start small to test we will move to 15 when reaching a final product

for epoch in range(num_epochs):
    print(f"\nEpoch {epoch+1}/{num_epochs}")
    # Train
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in tqdm(train_loader):
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)              # shape [batch, 2]
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    train_loss = running_loss / total
    train_acc = correct / total

    # Validate
    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            val_correct += (preds == labels).sum().item()
            val_total += labels.size(0)

    val_loss /= val_total
    val_acc = val_correct / val_total



    #save the history

    history["loss"].append(train_loss)
    history["val_loss"].append(val_loss)
    history["acc"].append(train_acc)
    history["val_acc"].append(val_acc)

    if val_loss < best_val_loss:
      torch.save(model.state_dict(), "best_model.pth")
      best_val_loss = val_loss
      print(f"New best model saved (val_loss = {best_val_loss:.4f})")

    # Print metrics
    print(f"Train Loss: {train_loss:.4f}  Train Acc: {train_acc:.4f}")
    print(f"Val   Loss: {val_loss:.4f}  Val   Acc: {val_acc:.4f}")

"""##EVALUATION"""

import matplotlib.pyplot as plt

# Plot Loss
plt.figure(figsize=(10,5))
plt.plot(history["loss"], label="Train Loss")
plt.plot(history["val_loss"], label="Validation Loss")
plt.title("Training vs Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Plot Accuracy
plt.figure(figsize=(10,5))
plt.plot(history["acc"], label="Train Accuracy")
plt.plot(history["val_acc"], label="Validation Accuracy")
plt.title("Training vs Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

model.load_state_dict(torch.load("best_model.pth", map_location=device))
model.to(device)
model.eval()

all_labels = []
all_preds = []
all_probs = []  # probability for class 1 (AI)

with torch.no_grad():
    for images, labels in val_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)           # logits [batch, 2]
        probs = torch.softmax(outputs, dim=1)[:, 1]  # P(class=1)

        _, preds = torch.max(outputs, 1)

        all_labels.append(labels.cpu().numpy())
        all_preds.append(preds.cpu().numpy())
        all_probs.append(probs.cpu().numpy())

# Concatenate all batches
all_labels = np.concatenate(all_labels)
all_preds  = np.concatenate(all_preds)
all_probs  = np.concatenate(all_probs)

# Metrics
acc  = accuracy_score(all_labels, all_preds)
prec = precision_score(all_labels, all_preds, pos_label=1)
rec  = recall_score(all_labels, all_preds, pos_label=1)
f1   = f1_score(all_labels, all_preds, pos_label=1)

print("Validation performance:")
print(f"Accuracy : {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall   : {rec:.4f}")
print(f"F1-score : {f1:.4f}")

print("\nClassification report:")
print(classification_report(all_labels, all_preds, target_names=["Real (0)", "AI (1)"]))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)

plt.figure(figsize=(5, 4))
sns.heatmap(cm,
            annot=True,
            fmt="d",
            cmap="Blues",
            xticklabels=["Real (0)", "AI (1)"],
            yticklabels=["Real (0)", "AI (1)"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix - Validation Set")
plt.tight_layout()
plt.show()

# ROC Curve + AUC
fpr, tpr, thresholds = roc_curve(all_labels, all_probs, pos_label=1)
auc = roc_auc_score(all_labels, all_probs)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle="--", label="Random")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Validation Set")
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()

"""###"""